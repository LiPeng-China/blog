import{_ as n,X as s,Y as a,Z as e}from"./framework-bf6cbb95.js";const t={},p=e(`<h2 id="一、face-alignment-使用错误" tabindex="-1"><a class="header-anchor" href="#一、face-alignment-使用错误" aria-hidden="true">#</a> 一、face_alignment 使用错误</h2><p>1、使用</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> face_alignment
face <span class="token operator">=</span> face_alignment<span class="token punctuation">.</span>FaceAlignment<span class="token punctuation">(</span>face_alignment<span class="token punctuation">.</span>LandmarksType<span class="token punctuation">.</span>_2D<span class="token punctuation">,</span> flip_input<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">&#39;cuda&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>2、报错如下</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:
  File <span class="token string">&quot;/data/LP2/lipreading-demo/video_process.py&quot;</span>, line <span class="token number">21</span>, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>
    face <span class="token operator">=</span> face_alignment.FaceAlignment<span class="token punctuation">(</span>face_alignment.LandmarksType._2D, <span class="token assign-left variable">flip_input</span><span class="token operator">=</span>False, <span class="token assign-left variable">device</span><span class="token operator">=</span><span class="token string">&#39;cuda&#39;</span><span class="token punctuation">)</span>
  File <span class="token string">&quot;/home/amax/.conda/envs/torch2/lib/python3.10/enum.py&quot;</span>, line <span class="token number">437</span>, <span class="token keyword">in</span> __getattr__
    raise AttributeError<span class="token punctuation">(</span>name<span class="token punctuation">)</span> from None
AttributeError: _2D
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>3、分析原因</p><p>LandmarksType 没有 _2D 属性</p><p>4、验证</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">(</span>torch2<span class="token punctuation">)</span> amax@amax:/data/LP2$ python
Python <span class="token number">3.10</span>.11 <span class="token punctuation">(</span>main, May <span class="token number">16</span> <span class="token number">2023</span>, 00:28:57<span class="token punctuation">)</span> <span class="token punctuation">[</span>GCC <span class="token number">11.2</span>.0<span class="token punctuation">]</span> on linux
Type <span class="token string">&quot;help&quot;</span>, <span class="token string">&quot;copyright&quot;</span>, <span class="token string">&quot;credits&quot;</span> or <span class="token string">&quot;license&quot;</span> <span class="token keyword">for</span> <span class="token function">more</span> information.
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token function">import</span> face_alignment
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> print<span class="token punctuation">(</span>dir<span class="token punctuation">(</span>face_alignment.LandmarksType<span class="token punctuation">))</span>
<span class="token punctuation">[</span><span class="token string">&#39;THREE_D&#39;</span>, <span class="token string">&#39;TWO_D&#39;</span>, <span class="token string">&#39;TWO_HALF_D&#39;</span>, <span class="token string">&#39;__class__&#39;</span>, <span class="token string">&#39;__doc__&#39;</span>, <span class="token string">&#39;__members__&#39;</span>, <span class="token string">&#39;__module__&#39;</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>5、解决</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>face <span class="token operator">=</span> face_alignment.FaceAlignment<span class="token punctuation">(</span>face_alignment.LandmarksType.TWO_D, <span class="token assign-left variable">flip_input</span><span class="token operator">=</span>False, <span class="token assign-left variable">device</span><span class="token operator">=</span><span class="token string">&#39;cuda&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="二、计算模型的参数两与运算量" tabindex="-1"><a class="header-anchor" href="#二、计算模型的参数两与运算量" aria-hidden="true">#</a> 二、计算模型的参数两与运算量</h2><p>1、安装 thop 包</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>pip <span class="token function">install</span> thop
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>2、使用</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> thop <span class="token keyword">import</span> profile<span class="token punctuation">,</span> clever_format

<span class="token keyword">def</span> <span class="token function">cal_flops_params</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    flops<span class="token punctuation">,</span> params <span class="token operator">=</span> profile<span class="token punctuation">(</span>model<span class="token punctuation">,</span> inputs<span class="token operator">=</span>inputs<span class="token punctuation">)</span>
    flops<span class="token punctuation">,</span> params <span class="token operator">=</span> clever_format<span class="token punctuation">(</span><span class="token punctuation">[</span>flops<span class="token punctuation">,</span> params<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">&quot;%.2f&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> flops<span class="token punctuation">,</span> params

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span>
	total_flops<span class="token punctuation">,</span> total_params <span class="token operator">=</span> cal_flops_params<span class="token punctuation">(</span>model<span class="token punctuation">,</span> inputs<span class="token operator">=</span><span class="token punctuation">(</span>video<span class="token punctuation">,</span> video_mask<span class="token punctuation">,</span> tgt<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="三、touch-no-grade-报错" tabindex="-1"><a class="header-anchor" href="#三、touch-no-grade-报错" aria-hidden="true">#</a> 三、touch.no_grade() 报错</h2><p>1、错误代码</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token decorator annotation punctuation">@staticmethod</span>
<span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span>			<span class="token comment">#! API 使用错误</span>
<span class="token keyword">def</span> <span class="token function">inference</span><span class="token punctuation">(</span>lips<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> LipReader<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model <span class="token operator">=</span> ModelInferenceUtil<span class="token punctuation">.</span>load_model_state<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token string">&quot;/path/to/checkpoint&quot;</span><span class="token punctuation">)</span>
    <span class="token comment"># data</span>
    lips<span class="token punctuation">,</span> lips_mask <span class="token operator">=</span> ModelInferenceUtil<span class="token punctuation">.</span>prepare_data<span class="token punctuation">(</span>lips<span class="token punctuation">)</span>
    <span class="token comment"># cpu --&gt; gpu</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    lips <span class="token operator">=</span> lips<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    lips_mask <span class="token operator">=</span> lips_mask<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># extract feature</span>
    c3d_feature <span class="token operator">=</span> ModelInferenceUtil<span class="token punctuation">.</span>extract_feature<span class="token punctuation">(</span>lips<span class="token punctuation">)</span>
    <span class="token comment"># inference</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    scores<span class="token punctuation">,</span> logits<span class="token punctuation">,</span> predict <span class="token operator">=</span> model<span class="token punctuation">(</span>c3d_feature<span class="token punctuation">,</span> lips_mask<span class="token punctuation">)</span>
    predict_text <span class="token operator">=</span> ModelInferenceUtil<span class="token punctuation">.</span>idx_to_hz<span class="token punctuation">(</span>predict<span class="token punctuation">)</span>
    <span class="token comment"># return</span>
    <span class="token keyword">return</span> predict_text
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>2、报错</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>File <span class="token string">&quot;/data/LP2/LipReaderClient/app/lipreader/util.py&quot;</span>, line <span class="token number">124</span>, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>
    class ModelInferenceUtil:
File <span class="token string">&quot;/data/LP2/LipReaderClient/app/lipreader/util.py&quot;</span>, line <span class="token number">131</span>, <span class="token keyword">in</span> ModelInferenceUtil
    def inference<span class="token punctuation">(</span>lips<span class="token punctuation">)</span>:
TypeError: no_grad.__init__<span class="token punctuation">(</span><span class="token punctuation">)</span> takes <span class="token number">1</span> positional argument but <span class="token number">2</span> were given
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>3、分析原因</p><p>touch.no_grade() 相关 API 使用错误，no_grade() 应为方法，而不是属性</p><p>4、更改</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token decorator annotation punctuation">@staticmethod</span>
<span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">inference</span><span class="token punctuation">(</span>lips<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> LipReader<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model <span class="token operator">=</span> ModelInferenceUtil<span class="token punctuation">.</span>load_model_state<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token string">&quot;/path/to/checkpoint&quot;</span><span class="token punctuation">)</span>
    <span class="token comment"># data</span>
    lips<span class="token punctuation">,</span> lips_mask <span class="token operator">=</span> ModelInferenceUtil<span class="token punctuation">.</span>prepare_data<span class="token punctuation">(</span>lips<span class="token punctuation">)</span>
    <span class="token comment"># cpu --&gt; gpu</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    lips <span class="token operator">=</span> lips<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    lips_mask <span class="token operator">=</span> lips_mask<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># extract feature</span>
    c3d_feature <span class="token operator">=</span> ModelInferenceUtil<span class="token punctuation">.</span>extract_feature<span class="token punctuation">(</span>lips<span class="token punctuation">)</span>
    <span class="token comment"># inference</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    scores<span class="token punctuation">,</span> logits<span class="token punctuation">,</span> predict <span class="token operator">=</span> model<span class="token punctuation">(</span>c3d_feature<span class="token punctuation">,</span> lips_mask<span class="token punctuation">)</span>
    predict_text <span class="token operator">=</span> ModelInferenceUtil<span class="token punctuation">.</span>idx_to_hz<span class="token punctuation">(</span>predict<span class="token punctuation">)</span>
    <span class="token comment"># return</span>
    <span class="token keyword">return</span> predict_text
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="四、pyqt-报错" tabindex="-1"><a class="header-anchor" href="#四、pyqt-报错" aria-hidden="true">#</a> 四、PyQT 报错</h2><p>1、错误</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token punctuation">(</span>torch2<span class="token punctuation">)</span> amax@amax:/data/LP2/LipReaderClient$ python demo.py 

 Tips: QFluentWidgets Pro is now released. Click https://qfluentwidgets.com/pages/pro to learn <span class="token function">more</span> about it.

QObject::moveToThread: Current thread <span class="token punctuation">(</span>0x1089de0<span class="token punctuation">)</span> is not the object&#39;s thread <span class="token punctuation">(</span>0x6ea6c90<span class="token punctuation">)</span>.
Cannot move to target thread <span class="token punctuation">(</span>0x1089de0<span class="token punctuation">)</span>

qt.qpa.plugin: Could not load the Qt platform plugin <span class="token string">&quot;xcb&quot;</span> <span class="token keyword">in</span> <span class="token string">&quot;/home/amax/.conda/envs/torch2/lib/python3.10/site-packages/cv2/qt/plugins&quot;</span> even though it was found.
This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.

Available platform plugins are: xcb, linuxfb, minimal, offscreen, vnc, webgl.

Aborted <span class="token punctuation">(</span>core dumped<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>2、分析原因</p><p><code>opencv</code> 与 <code>pyqt5</code> 一起使用时，会出现此问题。</p><p><code>opencv</code> 内部使用的 qt 插件与 <code>pyqt5</code> 不兼容。</p><p>3、解决办法</p><p>在 <code>import cv2</code> 语句之后取消设置环境变量：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os
os<span class="token punctuation">.</span>environ<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">&quot;QT_QPA_PLATFORM_PLUGIN_PATH&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="" tabindex="-1"><a class="header-anchor" href="#" aria-hidden="true">#</a></h2>`,35),o=[p];function i(c,l){return s(),a("div",null,o)}const r=n(t,[["render",i],["__file","PyTorch.html.vue"]]);export{r as default};
